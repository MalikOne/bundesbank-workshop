---
title: "Basics and CART: Exercise"
output: html_notebook
---

This notebook walks you through the exercise for the supervised learning I session.

## Setup

```{r}
library(rpart)
library(partykit)
library(caret)
library(PRROC)
```

In this exercise, we use a reduced version of the BACH data set.

```{r}
load("BACH.Rda")
```

## Data preparation

As a starting point, we begin with summarizing all variables to get a first impression of the data.

```{r}

```

Our machine learning task is to predict whether a corporation experiences a net loss in the year 2015. For this setting, we first compute a dummy variable which indicates a loss with "1" and returns a "0" otherwise, based on the variable `bach$net_profit_or_loss`. The `ifelse` function might be helpful.

```{r}

```

Then we split the data set into a training and test part. However, now we use the year 2015 for the test set and all remaining years for training.

```{r}

```

## CART

### Grow and prune tree

In order to build a classification tree with the training data, the `rpart` function can be used again. As the outcome variable, we plug in the new variable we created earlier. If this variable is of class factor, `rpart` adapts to this format and grows a classification tree (instead of a regression tree). Use all variables besides `net_profit_or_loss` and `return_on_equity` as predictors, e.g. via `outcome ~ . - net_profit_or_loss - return_on_equity`. It is useful to set the random number seed first.

```{r}

```

For pruning, we need the `cp` value of the best subtree. Here we prepare pruning according to the 1-Standard Error Rule.

```{r}

```

Now prune the classification tree.

```{r}

```

### Variable Importance and Plot

We can inspect the tree results by plotting the pruned classification tree. However, be prepared that also pruned trees can be quite large.

```{r}

```

The `varImp` function is useful for listing the importance of each predictor variable for reducing node impurity.

```{r}

```

## Prediction

For evaluating performance, we predict the outcome in the test set in two formats. We want to use `predict` for predicting class membership and also for computing predicted probabilities. Therefore, two prediction objects are generated.

```{r}

```

Given predicted class membership, we can use the function `confusionMatrix` for evaluating our classification model.

```{r}

```

Additionally, ROC curves are helpful for evaluating prediction performance with categorical outcomes. Here we could (e.g.) use the `PRROC` package, which has a function called `roc.curve`.

```{r}

```

Finally, we can print and plot the resulting roc object.

```{r}

```
